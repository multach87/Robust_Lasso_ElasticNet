---
title: 'Process Coefficients from All Adaptations and Data Splits'
author: "Matt Multach"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: false
bibliography: Component_Refs.bib
#output: 
#       xaringan::infinite_moon_reader:
#              lib_dir: lib
#              highlightStyle: github
#              highlightLines: true
#              countIncrementalSlides: false
#              beforeInit: "macros.js"
#              css: [default, tamu, tamu-fonts]
---

## Introduction

This document demonstrates the processing of model coefficients from a list of multiple model objects produced by the previous **<span style = "color:blue">`` `r "hqmsa.sim.funct()"` ``</span>** function. Note that this document walks through the processing of coefficient results from _all_ lasso and elastic net adaptations applied to the 100 data splits. There are therefore a few more steps involved compared to 04A_Process_Coefficients_SingleAdapt. Furthermore, the final results will be stored to save time for future demos.

## Preamble and Setup

```{r setup, message = FALSE , warning = FALSE , include=FALSE}
knitr::opts_chunk$set(echo = TRUE , eval = TRUE)
```

### A note on formatting

This document makes use of **bolding**, _italics_, and "quotations" to help distinguish different types of items being referenced.

 * **bolding** will be used when referencing a new term or concept for the first time. Subsequent references to each term/concept will _not_ be bolded.
 * _italics_ will be used primarily for emphasis.
 * 'single quotations' will be used to clarify specific arguments for a function, or specific parameters of a mathemtical/statistical formulation
 * Inline references to code (functions, objects, specific commands, etc.) will use **<span style = "color:blue">`` `r "code_chunk_formatting"` ``</span>** in **<span style = "color:blue">`` `r "bolded blue font"` ``</span>**
 * Inline references to packages will similarly use *<span style = "color:red">`` `r "code_chunk_formatting"` ``</span>*, except in *<span style = "color:red">`` `r "italicized red font"` ``</span>*
 
Re: spacing and line breaks - I'm pretty heterogeneous in my application of line breaks and spacing, in a way that is idiosyncratic to my own code practice. The most important aspects of my spacing and line breaks are detailed below

I generally put spaces between code inputs I consider "sufficiently distinct". This improves readability generally, but I find it particularly helpful for debugging. Note, however, that spaces are generally trivial in between distinct code inputs in R, although this is not universally the case. Multi-character code inputs, such as the pointer **<span style = "color:blue">`` `r "<-"` ``</span>** and most logical operators, _cannot_ include spaces in between components of the code input. Note also that whitespace *is* meaningful in other programming languages, and so this convention should be considered with caution in your own practice.

Generally, I use line breaks to:

 * Break up separate arguments for a single command/function or chain of operations
 * To clearly distinguish between different closing parentheses, brackets, squigglies, etc., since RStudio will automatically tab each closing piece to match its opener.
 
### Packages

Let's load the necessary packages. Links to more information about each packages and helpful guides (where applicable) can be found in 00B_Package_Descr_Refs. Appropriate references for each package can be found in the "References" section at the end of this document.

```{r libraries , warning = FALSE , message = FALSE}
# This chunk loads the packages used in this workbook
library(xaringan)   # Allows active preview of report in RStudio
library(mvtnorm)    # Generates multivariate-normal data
library(magrittr)   # Used for piping
library(purrr)      # Used for mapping functions efficiently
library(data.table) # For more streamlined data structures
library(glmnet)     # For general lasso/elastic net functionality
library(hqreg)      # For LAD/Huber-loss regularization with SNCD algorithm
library(rlang)      # For parse_expr() to parse data name in k-fold subsetting functions
library(msaenet)    # For the multi-step adaptive elastic net
```

---
nocite: |
  @magrittr , @purrr , @xaringan , @mvtnorm , @data.table , @glmnet , @hqreg , @rlang , @msaenet
---

### Load and Process 10-Split Model Data

Let's also load our model data. Note that this is a collection of all adaptations run 

```{r load model results}
models_all <- readRDS("/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/models100.RData")
```

## Extracting Coefficient Information

### Coefficient frequency function

There are many pieces of information that might be extracted from such a rich collection of model results. Let's focus, however, on predictor selection/inclusion frequency.

I'd like to add a list element that contains information about the adaptive LAD lasso models across all data splits, particularly with respect to coefficient inclusion frequency. Note that this does _not_ include intercepts, given that some models do not include them.

Also note that this function relies on a list with a comparable structure to my processed models:
 
 * Level 1 of the list corresponds with each data split
 * Level 2 of the list corresponds with different model result objects from a given data split
   * One list element at Level 2 contains the model summary object 'model.info'
     * which contains a list element 'coefs', a numeric vector of coefficient values (and intercept, if applicable)

```{r extract coefficient information}
coefs_freq <- function(models) {
       # initialize vector of predictor selection frequency, with all values set to 0
       coefs.freq <- numeric(length = 8)
       
       # label frequency vector with predictor names, accounting for 
       names(coefs.freq) <- names(models[[1]][["model.info"]][["coefs"]][-1])
       
       # update each predictors' selection frequency if the corresponding coefficient value
       # # in each data split is nonzero (aka, was selected into the model)
       for(i in 1:length(models)) {
              for(j in 1:length(coefs.freq)) {
                     if(models[[i]][["model.info"]][["coefs"]][(j + 1)] != 0) {
                            coefs.freq[j] <- coefs.freq[j] + 1
                     }
              }
       }
       
       return(coefs.freq)       
}
```

### Minor functions

I'd like to count the number of variables with $100\%$ or $0\%$ selection for each adaptation. I'm going to create two basic functions that I can apply during piping to generate these values.

```{r all_splits function}
all_splits <- function(data) {
        return(length(which(data[1:8] == 100)
                      )
               )
}
```

```{r no_splits function}
no_splits <- function(data) {
        return(length(which(data[1:8] == 0)
                      )
        )
}
```

Similarly, I would like to calculate the number of adaptations which selected each variable $100\%$ and $0\%$ of the time.

```{r adapts_100 function}
adapts_100 <- function(data) {
        return(length(which(data[1:7] == 100)
                      )
               )
}
```

```{r adapts_0 function}
adapts_0 <- function(data) {
        return(length(which(data[1:7] == 0)
                      )
        )
}
```

### Coefficient processing: Initialize list

Our new list element will have two data.tables:
 
 * A data.table of selection frequencies by adaptation (rows = lasso/elastic net adaptation)
 * A data.table of selection frequencies by potential predictor (rows = potential predictor X1 - X8) 

Let's initialize that list.

```{r make Frequencies list object in full model list}
models_all[["Frequencies"]] <- list()
```

### Coefficient frequency processing: By Adaptation

Now let's map our coefficient frequency function across all adaptations and model results to create our first data.table. Rather than include # comments in the code itself to describe each step, I will walk through the operations line-by-line below.

```{r run coef frequency function by adaptation}
models_all[["Frequencies"]][["By_Adaptation"]] <- models_all[1:7] %>%
         map(coefs_freq) %>%
         setDT %>%
         t %>%
         data.frame %>%
         setDT %>%
         .[ , "all" := apply(. , 1 , all_splits)] %>%
         .[ , "none" := apply(. , 1 , no_splits)] %>%
         .[ , "method" := names(models_all[-8])] %>%
         setkey(. , method) 
```

Let's walk through what's going on in the last code chunk. 
  
  * First, establish reference to the **<span style = "color:blue">`` `r "models_all"` ``</span>** object for the subsequent pipe operations
  * Second, **<span style = "color:blue">`` `r "map()"` ``</span>** the **<span style = "color:blue">`` `r "coefs_freq()"` ``</span>** function across elements of **<span style = "color:blue">`` `r "models_all"` ``</span>**
  * Third, make the resulting object a data.table using **<span style = "color:blue">`` `r "setDT()"` ``</span>** function
  * Fourth, transpose the result using **<span style = "color:blue">`` `r "t()"` ``</span>**, since the result will be an $8 x 7$ object with rows corresponding with each possible predictor and columns corresponding with each model/adaptation
    * As a reminder, our desired object is a $7 x 8$ object, with model/adaptation in each row and possible predictor frequency in each column
  * Fifth, make the result a dataframe
  * Sixth, make the result a data.table, _again_
    * I can't quite explain why we need to conduct the steps above in the exact order (and repetition) in the pipes above. There's a sequence of transformations on the unstored/transitory object that impact what the result will be that mean **<span style = "color:blue">`` `r "t()"` ``</span>** has to go in the middle, and **<span style = "color:blue">`` `r "data.frame()"` ``</span>** at the end. But then we have to reset the object as a data.table after **<span style = "color:blue">`` `r "data.frame()"` ``</span>**.
  * Seventh, create a column of $100\%$-selection variables by mapping the **<span style = "color:blue">`` `r "all_splits()"` ``</span>** function over the rows of our intermediate data.table
  * Eighth, create a column of $0\%$-selection variables by mapping the **<span style = "color:blue">`` `r "no_splits()"` ``</span>** function over the rows of our intermediate data.table
  * Ninth, make a column indicating the adaptation for each row

Because I'm currently learning about keys, the last operation of the pipe sets a key for the **<span style = "color:blue">`` `r "\"Frequencies\""` ``</span>** data.table based on the method/adaptation. (If you don't know what this means, don't worry too much about it. It won't generally come up for the purposes of demonstrating my combined model. Right now its only practical significance is alphabetically sorting **<span style = "color:blue">`` `r "\"Frequencies\""` ``</span>** by method/adaptation).

Let's take a quick look at the structure of our coefficient frequencies object. Note that if we had not set the key, the final line would not be present. This tells us that the data.table is sorted by the character values in **<span style = "color:blue">`` `r "\"method\""` ``</span>**.

```{r Frequencies By Adaptation str}
str(models_all[["Frequencies"]][["By_Adaptation"]])
```




### Coefficient frequency processing: By Potential Predictor

Now we're going to do the same thing, except by predictor instead of adaptation. This is actually pretty easily adapted from the script used to generate a data.table by adaptation. We can just eliminate the transpose ( **<span style = "color:blue">`` `r "t()"` ``</span>** ) step of the pipe. As a result, we can also get rid of the initial **<span style = "color:blue">`` `r "setDT()"` ``</span>** step, as it is now redundant. The only other meaningful changes:
  
  * change 'all'/'none' columns to map the **<span style = "color:blue">`` `r "adapts_100()"` ``</span>** & **<span style = "color:blue">`` `r "adapts_0()"` ``</span>** functions instead of the previous **<span style = "color:blue">`` `r "all_splits()"` ``</span>** & **<span style = "color:blue">`` `r "no_splits()"` ``</span>** functions
  * Replace the 'method' column with a 'predictor' column indicating the potential predictor with which each data.table row corresponds

```{r run coef frequency function by predictor}
models_all[["Frequencies"]][["By_Predictor"]] <- models_all[1:7] %>%
        map(coefs_freq) %>%
        data.frame %>%
        setDT %>%
        .[ , "all" := apply(. , 1 , adapts_100)] %>%
        .[ , "none" := apply(. , 1 , adapts_0)] %>%
        .[ , "predictor" := names(models_all[["Frequencies"]][["By_Adaptation"]])[1:8]] %>%
        setkey(. , predictor) 
```

Let's take a look at the new data.table using **<span style = "color:blue">`` `r "str()"` ``</span>**.

```{r Frequencies By Predictor str}
str(models_all[["Frequencies"]][["By_Predictor"]])
```

## Save the Last ~~Dance~~ File

Let's save the model results file which also includes our new "Frequencies" data.table so that we can load it during the full walkthrough.

```{r save frequencies file}
saveRDS(models_all , "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/models100_plus_freqs.RData")
```

## References
