---
title: "Data_Generation"
author: "Matt Multach"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: false
bibliography: Component_Refs.bib
#output: 
#       xaringan::infinite_moon_reader:
#              lib_dir: lib
#              highlightStyle: github
#              highlightLines: true
#              countIncrementalSlides: false
#              beforeInit: "macros.js"
#              css: [default, tamu, tamu-fonts]
---

## Introduction

This file walks through the steps used to simulate data generated by a linear model for my dissertation research.

## Preamble and Setup

```{r setup, message = FALSE , warning = FALSE , include=FALSE}
knitr::opts_chunk$set(echo = TRUE , eval = TRUE)
```

### A note on formatting

This document makes use of **bolding**, _italics_, and "quotations" to help distinguish different types of items being referenced.

 * **bolding** will be used when referencing a new term or concept for the first time. Subsequent references to each term/concept will _not_ be bolded.
 * _italics_ will be used primarily for emphasis.
 * 'single quotations' will be used to clarify specific arguments for a function, or specific parameters of a mathemtical/statistical formulation
 * Inline references to code (functions, objects, specific commands, etc.) will use **<span style = "color:blue">`` `r "code_chunk_formatting"` ``</span>** in **<span style = "color:blue">`` `r "bolded blue font"` ``</span>**
 * Inline references to packages will similarly use *<span style = "color:red">`` `r "code_chunk_formatting"` ``</span>*, except in *<span style = "color:red">`` `r "italicized red font"` ``</span>*
 
Re: spacing and line breaks - I'm pretty heterogeneous in my application of line breaks and spacing, in a way that is idiosyncratic to my own code practice. The most important aspects of my spacing and line breaks are detailed below

I generally put spaces between code inputs I consider "sufficiently distinct". This improves readability generally, but I find it particularly helpful for debugging. Note, however, that spaces are generally trivial in between distinct code inputs in R, although this is not universally the case. Multi-character code inputs, such as the pointer **<span style = "color:blue">`` `r "<-"` ``</span>** and most logical operators, _cannot_ include spaces in between components of the code input. Note also that whitespace *is* meaningful in other programming languages, and so this convention should be considered with caution in your own practice.

Generally, I use line breaks to:

 * Break up separate arguments for a single command/function or chain of operations
 * To clearly distinguish between different closing parentheses, brackets, squigglies, etc., since RStudio will automatically tab each closing piece to match its opener.

### Packages

First, let's load the necessary packages. Links to more information about each packages and helpful guides (where applicable) can be found in 00B_Package_Descr_Refs. Appropriate references for each package can be found in the "References" section at the end of this document.

```{r libraries , warning = F , message = F}
# This chunk loads the packages used in this workbook
library(xaringan)   # Allows active preview of report in RStudio
library(mvtnorm)    # Generates multivariate-normal data
library(magrittr)   # Used for piping
library(purrr)      # Used for mapping functions efficiently
library(data.table) # For more streamlined data structures
```

---
nocite: |
  @magrittr , @purrr , @xaringan , @mvtnorm , @data.table
---

Note that if you do not have any of the listed packages, you should install them using **<span style = "color:blue">`` `r "install.packages(\"pkg-name-in-quotes-here\")"` ``</span>**.

### g-and-h Distribution

The **g-and-h distribution** is a common tool for studying robust properties in hypothesis-testing statistical frameworks. It is a generalization of the Normal distribution that adds two additional parameters for controlling skew and kurtosis. Those two parameters are 'g' and 'h', respectively, hence the name. See @Wilcox1990, @Wilcoxetal2013, @WilcoxRobust for more information.

A g-and-h distributed random variable takes the form:
$$
    \textit{W} = 
      \begin{cases} 
        \frac{exp(gZ)-1}{g}exp(\frac{hZ^2}{2}) & g>0,\\
        Zexp(\frac{hZ^2}{2}) & g=0
     \end{cases}
$$

This function generates values from the g-and-h distribution, where

 * _g_ is a parameter controlling distributional skew, ranging between 0 and 1 (inclusive)
 * _h_ is a similar parameter for kurtosis/distributional peakedness, also ranging between 0 and 1 (inclusive)
 * $Z \sim N(0,1)$ is the Standard Normal Distribution

I will not delve deeply into the formulation above. The above distribution function should appear vaguely familiar to anyone who knows the probability density function of the Normal distribution.

The R function below was adapted from the *<span style = "color:red">`` `r "WRS2"` ``</span>* package, @WRS2. 

```{r g-and-h distr function , eval = TRUE}
# Function for generating values from the g-and-h distribution
ghdist <- function(n , g = 0 , h = 0) {
  # generate n random values from a standard normal distribution     
  x <- rnorm(n , mean = 0 , sd = 1)
       
  # generate values if g > 0     
  if(g > 0) {
    ghdist <- (exp(g * x) - 1) * exp(h * x ^ 2 / 2) / g
    }
  
  # otherwise, generate if g = 0 (since dividing by 0 is...difficult)     
  if(g == 0) {
    ghdist <- x * exp( h * x ^ 2 / 2)
    }
  
  # save the object
  return(ghdist)
}
```

The following table provides some information on skew and kurtosis for different values of 'g' and 'h'. 

```{r gandh table , echo = F}
gandh <- setDT(data.frame(g = c(0.0 , 0.2 , 0.0 , 0.2) , 
                         h = c(0.0 , 0.0 , 0.2 , 0.2) , 
                         skew = c(0.00 , 0.61 , 0.00 , 2.81) , 
                         kurtosis = c(3.00 , 3.68 , 21.46 , 155.98)
                         )
              )
```

```{r gandh table display}
gandh
```

### Mixed Normal Distribution

In addition to the g-and-h distribution, we will be using another useful distribution for studying outliers: the **mixed normal distribution** (also known as the **contaminated normal distribution**). Although we will be implementing that distribution within the data-generating function itself, a brief introduction is helpful.

The mathematical representation of the mixed normal distribution for a random variable 'X' is:

$$
     X \sim (1-\eta_x)N(\mu_1,\sigma_1^2) + \eta_x N(\mu_2,\sigma_2^2),
$$

where
 
 * '~' denotes "has the following probability distribution"
 * $\eta_x$ denotes the proportion of outlier contamination in the random variables, ranging from 0 to 1
 * $N(\cdot)$ denotes a Normal distribution
 * $\mu_i$ and $\sigma_i^2$ denote the population mean and standard deviation for subpopulation $i$

## Data Simulation

### Data-Generating Function

This function will generate the simulated linear model data on which we will run the lasso and elastic net adaptations of interest. The arguments to **<span style = "color:blue">`` `r "data_gen()"` ``</span>** are simply the data characteristics of a dataset to be generated:

* 'n' = sample size
* 'p' = number of potential predictors
* 'eta_x' = proportion of outlier contamination in the potential predictor variables
* 'eta_y' = proportion of outlier contamination in response variable
* 'g' = amount of skew as imposed by the g-and-h distribution
* 'h' = amount of kurtosis/"peakedness" as imposed by the g-and-h distribution

In addition to these data characteristic arguments, the function also takes a random process seed and a tracking number. 

NOTE: In its current form, predictor contamination is induced before generating the response values. Consequently, predictor-space outliers will be model-supporting leverage points rather than model-detrimental leverage points.

```{r data-generating function}
data_gen <- function(n , p , eta_x , eta_y , g , h , 
                     seed , tracker) {      
  
  # create a data.table of the conditions of the current dataset
  conditions <- setDT(data.frame(n = n , p = p , 
                                 eta_x = eta_x , eta_y = eta_y , 
                                 g = g , h = h , tracker = tracker , 
                                 seed = seed))

  #create a p-column matrix containing the true coefficients
  betas <- matrix(0 , nrow = p , ncol = 1)
  betas[1,1] <- 0.5
  betas[2,1] <- 1.0
  betas[3,1] <- 1.5
  betas[4,1] <- 2.0
       
  # set seed for random process
  seed <- seed                       
       
  #generate covariance matrix
  covar.X <- matrix(rep(0 , p^2) , ncol = p)  
  # # put 1's along diagonal of covariance matrix
  diag(covar.X) <- 1 
       
  # generate uncontam. X values
  X.UC <- rmvnorm(floor((1 - eta_x)*n) , 
                  mean = rep(0 , p) , 
                  sigma = covar.X)
       
  # generate contaminated X/predictor values or 
  # # g-and-h-based X/predictor values
  if(((g == 0) & (h == 0))){
        # if there is predictor contamination, generate the
        # # contaminated values
        if(eta_x > 0) {                             
                X.C <- rmvnorm(ceiling(eta_x * n) , 
                               mean <- rep(10 , p) , 
                               sigma = covar.X)
                X <- rbind(X.UC , X.C)
        # otherwise, set the uncontaminated values to the
        # # full X dataset
        } else {
                X.C <- 0
                X <- X.UC
        }
              
        #generate uncontom. residuals
        err.UC <- rnorm(floor((1 - eta_y) * n) , mean = 0 , sd = 1)
        if(eta_y > 0) {  
                # if there is response contamination, generate the
                # # contaminated values
                err.C <- rnorm(ceiling(eta_y * n) , mean = 2 , sd = 5)
                err <- c(err.UC , err.C)
              } else {
                # otherwise, set the uncontaminated values to the
                # # final residuals
                err.c <- 0
                err <- err.UC
              }
       } else if(((g != 0) | (h != 0))) {
         # generates X/predictor values from g-and-h distribution
         # # with no outlier contamination
         X <- X.UC
         err <- ghdist(n = n , g = g , h = h)
       }
  
  #generate Y values from X matrix, 
  # # coefficients vector, and residuals vector
  Y <- X %*% betas[ , 1] + err                                    
  
  # Create list of separate components of generated data   
  combine <- list(conditions = conditions ,
                  tracker = tracker , 
                  seed = seed , 
                  betas = betas , 
                  X = setDT(data.frame(X)) , 
                  Y = setDT(data.frame(Y)) , 
                  err = err
                  )        
  
  #save combined list of all generated data
  return(combine)
}
```

You could easily plug in desired values for the data characteristics to generate a single dataset produced from those characteristics. However, generating multiple unique datasets from one characteristic set, or separate datasets with different underlying characteristic sets, requires a bit more work. The following sections work through the process that I used to both generate multiple iterations from the same characteristic set and repeat this process across many distinct sets of characteristics .

### Data.table of unique data conditions

 The current data will include the following characteristics:

* 'n' = sample size
  * Levels simulated: 38, 75, 150, 300
* 'p' = number of potential predictors
  * Levels simulated: 8, 30
* 'eta_x' = proportion of outlier contamination in the potential predictor variables
  * Levels simulated: 0.0, 0.1, 0.2 (0\%, 10\%, 20\%)
* 'eta_y' = proportion of outlier contamination in response variable
  * Levels simulated: 0.0, 0.1, 0.2 (0\%, 10\%, 20\%)
* 'g' = amount of skew as imposed by the g-and-h distribution
  * Levels simulated: 0.0, 0.2
* 'h' = amount of kurtosis/"peakedness" as imposed by the g-and-h distribution
  * Levels simulated: 0.0, 0.2
  
The following code chunk generates a data.table with each unique combination of data conditions. For the purposes of this example, outlier contamination and skew/kurtosis will be independently varied. Data will not be generated with both contamination and skew/kurtosis. Consequently, there will be a total of 96 unique data conditions.

* Outliers: 4 x 2 x 3 x 3 = 72 conditions
* Skew/Kurtosis: 4 x 2 x 3 = 24 conditions

```{r datatable of data conditions , eval = T}
# create an empty data.table to fill with data conditions
sim_structure.dt <- setDT(as.data.frame(matrix(ncol = 6 , nrow = 96)))

# specificy charactertic values
{
  # specify column names, aka the characteristics of interest     
  colnames(sim_structure.dt) <- c("n" , "p" , 
                                  "eta_x" , "eta_y" , 
                                  "g" , "h")
   
  # specify outlier contamination in potential predictors  
  sim_structure.dt[ , "eta_x"] <- c(rep(c(0.0 , 0.1 , 0.2) , 24) , 
                                    rep(0 , 24))
       
  # specify outlier contamination in the response
  sim_structure.dt[ , "eta_y"] <- c(rep(c(rep(0.0 , 3) , rep(0.1 , 3) , 
                                          rep(0.2 , 3)) , 8) , 
                                    rep(0 , 24))
       
  # specify number of potential predictors p
  sim_structure.dt[ , "p"] <- c(rep(c(rep(8 , 9) , rep(30 , 9)) , 4) , 
                                rep(c(rep(8 , 3) , rep(30 , 3)) , 4))
       
  # specify sample size n
  sim_structure.dt[ , "n"] <- c(rep(38 , 18) , rep(75 , 18) , 
                                rep(150 , 18) , rep(300 , 18) , 
                                rep(38 , 6) , rep(75 , 6) , 
                                rep(150 , 6) , rep(300 , 6))
       
  # specify skew parameter g
  sim_structure.dt[ , "g"] <- c(rep(0 , 72) , rep(c(0.2 , 0.0 , 0.2) , 
                                                  8))
  
  # specify kurtosis parameter h     
  sim_structure.dt[ , "h"] <- c(rep(0 , 72) , rep(c(0.0 , 0.2 , 0.2) , 
                                                  8))
}
```

And you can take a look at the resulting data.table. Running the command below will open a new tab in RStudio with a tabular display of the data. Given the nature of the function and its output, I have set code the following chunk to not evaluate in the final report.

```{r view sim conditions , eval = F}
View(sim_structure.dt)
```

We can also use the **<span style = "color:blue">`` `r "str()"` ``</span>** command to summarize the structure of the data.table.

```{r str simulation condition datatable}
str(sim_structure.dt)
```

### Generating the simulated data

Generating the complete collection of simulated data conditions involves using **<span style = "color:blue">`` `r "pmap()"` ``</span>** to map the data-generating function across rows containing argument inputs as columns for each data condition. The most straightforward way that I found to do so for all iterations of all data conditions would be to map this function across a repeated set of rows for each condition, corresponding with a data.table or similar object with a number of rows equal to the number of unique conditions times the number of iterations to be generated of each condition.

Previously, I conducted a series of steps to generate that full, repeated data.table upon which to **<span style = "color:blue">`` `r "pmap()"` ``</span>** the data-generating function. (Interested readers can scroll to the last section of this document to see the steps and code involved in the previous data-generating process). However, generating the data from this full table presents two obstacles to code cleanliness and efficiency:

 * First, multiple steps of extra code are present to generate that full data.table
 * Second, the full data.table is stored in memory as an object in RStudio
 
To that second point, the resulting object is not necessarily large here - only about2.9 mb, even with 48000 rows. However, scaling this process up many times over would result in an avoidable inefficiency on top of a large collection of data that is already going to be simulated. I consequently decided to try to **<span style = "color:blue">`` `r "pmap()"` ``</span>** the data-generating function without ever creating the repeated data.table, which can be seen in the code chunk below. 

This is all accomplished using **chaining**. @data.table's *<span style = "color:red">`` `r "data.table"` ``</span>* package allows you to conduct a non-simultaneous series of manipulations of a data object without storing each step to an object. Here, the series of manipulations I need to conduct are:

 1. Create a repeated sequence of each of the 96 unique data conditions corresponding with the desired number of iterations (500)
 2. Add columns for:
     * A progress tracker (1 - 48,000)
     * A seed for replicating the random processes generating each individual dataset (one seed for each of the 48,000 datasets)
 3. Remove any columns not corresponding with arguments to be passed to the **<span style = "color:blue">`` `r "data_gen()"` ``</span>** function that will be subsequently mapped
 
Note that each number in the list above corresponds with a different 'link' in the chain - aka, a separate step of operations on the original data. 

But why can't these steps all be conducted in a single step? Let's break down what each step is doing. The first step takes the original 96 rows as inputs and repeats them 500 times. The 48,000-length version of the data.table does not yet exist. Consequently, the addition of the 48,000-length tracker and seeds in the same step would create issues. Hence, these two operation sets need to be separated.

In the third step, we're removing two extra columns that arise during the operations being conducted on our data.table. The first is a column ':' indicating the row number from the original data.table from which each new row was populated. The second extra column 'iter' was created in previous links of the chain to facilitate generation of 500 iterations of each data condition. Neither of these columns correspond with arguments in our **<span style = "color:blue">`` `r "dat_gen()"` ``</span>** function and thus will produce errors if included when using **<span style = "color:blue">`` `r "pmap()"` ``</span>**. _However_, both columns play a role in the chain of operations being conducted. Furthermore, we can't delete these columns until _after_ they've occurred in the first place - hence, requiring a third step for removal.

Finally, we need to map our **<span style = "color:blue">`` `r "data_gen()"` ``</span>** function across this table to generate the full span of simulated datasets. We do all this without ever storing our manipulated data.table by using the %>% pipe on the chained set of manipulations.

NOTE: I do not include comments in the code chunk itself due to the relative complexity of the code and its single-command nature. Some notes are worth emphasizing here, though:
 
 * **<span style = "color:blue">`` `r ".SD"` ``</span>** is used by the *<span style = "color:red">`` `r "data.table"` ``</span>* package to denote all columns of the data.table being indexed, with the exception of anything specified with a subsequent 'by' argument
 * Data.table indices can contain three comma-separated values, compared to the two found in most R matrix- or data.frame-type objects:
   * The first and second values are _names_ of rows and columns, respectively
   * The third value is used to pass additional arguments or manipulations of a data.table, such as 'by'
   * *<span style = "color:red">`` `r "data.table"` ``</span>* does not use numeric position indices for row or column by default. However, you can specify 'with = F' in the third value in brackets to refer to columns or rows by numeric position


```{r map simulation function across unstored datatable of repeated data conditions , eval = F}
full.data <- setDT(sim_structure.dt[ , cbind(.SD , 
                                             iter = 1:500) , 
                                     by = 1:96][ , cbind(.SD , 
                                                         tracker = 1:(96 * 500) , 
                                                         seed = sample(x = c(-1e6:1e6) , 
                                                                       size = (96 * 500) , 
                                                                       replace = FALSE)
                                                         )][ , !c(1 , 8) , with = F]) %>%
  pmap(data_gen)
```

#### Data-generating wrapper

Changing the number of desired iterations would just be a matter of replacing any instances of 500 above with the desired number. We could also create a wrapper around our data-generating function that incorporates the chaining and piping in the previous chunk and accomplishes this with a single function argument. I've also updated some of the operations so be able to handle different numbers of unique data conditions besides the 96 we have in the current example.

```{r data gen chain pipe wrapper , eval = F}
data_gen.full <- function(data , iters = 500) {
  # data.table chained operations + pmap()
  full.data <- setDT(sim_structure.dt[ , cbind(.SD , 
                                               iter = 1:iters) , 
                                       by = 1:nrow(data)][ , 
                                                           cbind(.SD , 
                                                                 tracker = 1:(nrow(data) * iters) ,
                                                                 seed = sample(x = c(-1e6:1e6) , 
                                                                               size = (nrow(data) * iters) , 
                                                                               replace = FALSE)
                                                                 )
                                                           ][ , !c(1 , 8) , with = F]) %>%
    pmap(data_gen)
  
  #store the resulting object
  return(full.data)
}
```

### Processing and saving the data

If you want to save the resulting data as an **<span style = "color:blue">`` `r ".RData"` ``</span>** file, run the following chunk, specifying the appropriate file path. Note that this chunk will not automatically be evaluated when you knit this file. You must either change the eval argument for the code chunk to 'eval = T' or run the code within the chunk independently (after specifying the appropriate path). 

```{r save simulated data , eval = F}
saveRDS(full.data , "FILE/PATH/TO/DESIRED/FOLDER/NAME/fulldata.RData")
```

For use with subsequent demos of the multiple-adaptation procedure, I will be saving 100 random datasets from this full dataset. I've also included the vector of 100 random indices and the vector-generating seed for those indices for transparency.

```{r save 100 random datasets , eval = F}
#set the seed
set.seed(501)

#vector of 10 indices
data.100 <- sample(x = c(1:48000) , size = 100 , replace = F)

#save 100 from full data
saveRDS(full.data[data.100] , "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/Testing100.RData")
```

Many of the lasso/elastic net functions used in the multiple-adaptation procedure that I will be demo'ing rely on matrices rather than data.tables. Let's also create a version of this data file in which the X's are in matrix format.

In words, the following chunk is specifying a new objects **<span style = "color:blue">`` `r "testing100.mtx"` ``</span>**, which will result from the testing100 iterations of the full dataset. More specifically, it will extract just those iterations, but will apply the **<span style = "color:blue">`` `r "as.matrix()"` ``</span>** function to the appropriate list elements of each data iteration. Even more specifically, it applies as.matrix to elements 5 and 6 of each data iteration, which correspond with the X and Y data.tables, respectively.

```{r testing100 X matrices , eval = F}
# set up the new object and start the pipe '%>%'
testing100.mtx <- full.data[data.100] %>%
  # 'lapply()' applies a certain function over all list elements
  # # in the pre-existing object specified before the pipe
  lapply(map_at , 
         # and these subsequent arguments correspond with the 
         # # function being lapply'ed
         .at = c(5 , 6) , as.matrix)

#save 100 from full data
saveRDS(testing100.mtx , "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/Testing100_Xmtx.RData")
```

Let's also extract and process a single dataset, save it, and then do the same for a matricized version as we did above.

```{r extract and save single dataset and mtx version , eval = F}
# set random seed
set.seed(501)

# random index for choosing dataset from full data
data.1 <- sample(x = c(1:48000) , size = 1 , replace = F)

# extract single dataset
testing1 <- full.data[data.1]

# save applied dataset
saveRDS(testing1 , "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/Testing1_10152021.RData")

# "matricize" data.tables
testing1.mtx <- testing1 %>%
  lapply(map_at , 
         .at = c(5 , 6) , as.matrix)

#save 1 from full data
saveRDS(testing1.mtx , "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/Testing1_Xmtx_10152021.RData")
```

Finally, since I'm going to be creating demos for use with applied datasets, let's make a version that is as close to a real dataset as possible and save it. This mainly means I'm going to strip away the metadata I added for simulation purposes. I will make versions using both data.tables and matrices, and then I will save each version of the "applied" dataset.

```{r applied datasets and save , eval = F}
# create data.table version of "applied" dataset
testingapplied <- list(X = testing1[[1]][["X"]] , 
                       Y = testing1[[1]][["Y"]])

# save data.table version of "applied" dataset
saveRDS(testingapplied ,
        "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/TestingApplied_10152021.RData")

# create matrix version
testingapplied.mtx <- list(X = testing1.mtx[[1]][["X"]] , 
                           Y = testing1.mtx[[1]][["Y"]])

# save matrix version
saveRDS(testingapplied.mtx ,
        "/Users/Matt/Desktop/GitHub_Dissertation_Scripts/Robust_Lasso_ElasticNet/Datasets/TestingApplied_Xmtx_10152021.RData")


```

## DEPRECATED: Repeated data.table object for **<span style = "color:blue">`` `r "pmap()"` ``</span>**

### Create repeated data.table

The following chunks will generate a data.table with multiple rows per data condition. Each data condition will therefore have a number of rows equal to the number of simulated iterations. This is primarily used for convenience with the data-generating functions.

The resulting data.table should have a number of rows equal to the number of unique conditions times the number of iterations being simulated for each condition. Here, there are 72 + 24 = 96 unique conditions and we are simulating 500 iterations of each condition, resulting in 48000 total datasets/rows. We are also adding an additional column for the data-generating seed.

```{r create empty data.table , eval = F}
# create empty df
sim_repped.dt <- setDT(as.data.frame(matrix(ncol = 1 , nrow = (96*500))))
```

Now fill the empty data.table with repeated conditions

```{r fill empty data.table with conditions , eval = F , warning = F}
# fill empty df with repeated data conditions
for(i in 1:nrow(sim_structure.dt)) {
       sim_repped.dt[ ((500*(i - 1)) + 1): (500*i) , 
                      ':=' (n = sim_structure.dt[i , n] , 
                            p = sim_structure.dt[i , p] , 
                            eta_x = sim_structure.dt[i , eta_x] ,
                            eta_y = sim_structure.dt[i , eta_y] , 
                            g = sim_structure.dt[i , g] , 
                            h = sim_structure.dt[i , h])]
}

```

Finally, generate a seed for each iteration and a tracker number for each iteration. The tracker number will give us a sense of our progress if we run across the entire simulated data. This tracker will simply be the numbers 1 through 48000. Let's also get rid of the blank column from initializing the data.table.

```{r fill seeds column , eval = F}
# generate random seeds
set.seed(501)
sim_repped.dt[ , seed := runif(n = nrow(sim_repped.dt) , 
                               min = -1e10 , 
                               max = 1e10)]

# generate iteration tracker number
sim_repped.dt[ , tracker := c(1:48000)]

# get rid of blank first column
sim_repped.dt <- sim_repped.dt[ , !1 , with = F]
```

## References
