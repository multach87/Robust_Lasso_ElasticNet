---
title: "Full Applied Walkthrough"
author: "Matt Multach"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: false
bibliography: Component_Demos/Component_Refs.bib
---

## Preamble and Setup {.unlisted .unnumbered}

```{r setup, message = FALSE , warning = FALSE , include=FALSE}
knitr::opts_chunk$set(echo = TRUE , eval = TRUE)
```

## Introduction

This file demonstrates a simplified example of concerns studied in robust hypothesis testing and statistical methods. These issues motivated my dissertation research and this repository more broadly.

#### A note on formatting

This document makes use of **bolding**, _italics_, and "quotations" to help distinguish different types of items being referenced.

 * **bolding** will be used when referencing a new term or concept for the first time. Subsequent references to each term/concept will _not_ be bolded.
 * _italics_ will be used primarily for emphasis.
 * 'single quotations' will be used to clarify specific arguments for a function, or specific parameters of a mathemtical/statistical formulation
 * Inline references to code (functions, objects, specific commands, etc.) will use **<span style = "color:blue">`` `r "code_chunk_formatting"` ``</span>** in **<span style = "color:blue">`` `r "bolded blue font"` ``</span>**
 * Inline references to packages will similarly use *<span style = "color:red">`` `r "code_chunk_formatting"` ``</span>*, except in *<span style = "color:red">`` `r "italicized red font"` ``</span>*
 * References to other documents in this repository will use <span style = "color:green">`` `r "code_chunk_formatting"` ``</span> in <span style = "color:green">`` `r "un-italicized, un-bolded, green font"` ``</span>
 
Re: spacing and line breaks - I'm pretty heterogeneous in my application of line breaks and spacing, in a way that is idiosyncratic to my own code practice. The most important aspects of my spacing and line breaks are detailed below.

I generally put spaces between code inputs I consider "sufficiently distinct". This improves readability generally, but I find it particularly helpful for debugging. Note, however, that spaces are generally trivial in between distinct code inputs in R, although this is not universally the case. Multi-character code inputs, such as the pointer **<span style = "color:blue">`` `r "<-"` ``</span>** and most logical operators, _cannot_ include spaces in between components of the code input. Note also that whitespace *is* meaningful in other programming languages, and so this convention should be considered with caution in your own practice.

Generally, I use line breaks to:

 * Break up separate arguments for a single command/function or chain of operations
 * To clearly distinguish between different closing parentheses, brackets, squigglies, etc., since RStudio will automatically tab each closing piece to match its opener.

#### Packages

First, let's load the necessary packages. Links to more information about each packages and helpful guides (where applicable) can be found in <span style = "color:green">`` `r "00B_Package_Descr_Refs"` ``</span>. Appropriate references for each package can be found in the "References" section at the end of this document.

```{r libraries , warning = FALSE , message = FALSE}
# This chunk loads the packages used in this workbook
library(xaringan)   # Allows active preview of report in RStudio
library(psych)      # A package with some practical stats function
library(stats)      # Another library of practical stats functions.
library(magrittr)   # Used for piping
library(purrr)      # Used for mapping functions efficiently
library(data.table) # For more streamlined data structures
library(rlang)      # For parse_expr() to parse data name in k-fold subsetting functions
library(gridExtra)    # For displaying grids of objects
library(grid)         # For creating a title for multiplot grid
library(ggplot2)      # For generating and manipulation graphical objects
```

---
nocite: |
  @magrittr , @psych , @stats , @purrr , @xaringan , @data.table , @rlang , 
  @gridExtra , @grid , @ggplot2 , @magrittr
---

Note that if you do not have any of the listed packages, you should install them using **<span style = "color:blue">`` `r "install.packages(\"pkg-name-in-quotes-here\")"` ``</span>**.

# ALL THE CODE

```{r all the code}
#Load function for generating data from the g-and-h distribution
ghdist <- function(n,g=0,h=0){
       #
       # generate n observations from a g-and-h dist.
       #
       x<-rnorm(n)
       if (g>0){
              ghdist<-(exp(g*x)-1)*exp(h*x^2/2)/g
       }
       if(g==0)ghdist<-x*exp(h*x^2/2)
       ghdist
}

#Generate "population" data from each distribution
normal.pop <- rnorm(10000)
heavy.pop <- c(rnorm(9000) , rnorm(1000 , sd = 15))
outlier.pop <- c(rnorm(9000) , rnorm(1000 , mean = 10))
g0h0.pop <- ghdist(n = 10000 , g = 0 , h = 0)
g2h0.pop <- ghdist(n = 10000 , g = 0.2 , h = 0)
g0h2.pop <- ghdist(n = 10000 , g = 0 , h = 0.2)
g2h2.pop <- ghdist(n = 10000 , g = 0.2 , h = 0.2)
#combine separate population vectors into a single list 
# #for convenience with subsequent simulation functions
full.pop <- list(normal = list(distribution = "normal" , population = normal.pop) , 
                 heavy = list(distribution = "heavy" , population = heavy.pop) , 
                 outlier = list(distribution = "outlier" , population = outlier.pop) , 
                 g0h0 = list(distribution = "g0h0" , population = g0h0.pop) , 
                 g2h0 = list(distribution = "g2h0" , population = g2h0.pop) , 
                 g0h2 = list(distribution = "g0h2" , population = g0h2.pop) , 
                 g2h2 = list(distribution = "g2h2" , population = g2h2.pop))


#generate dataframe with conditions for simulations
sim.conds <- as.numeric(rep(seq(from = 10 , 
                                to = 500 , by = 10) , 7)) %>% #sample sizes
       cbind(as.numeric(rep(5000 , 7*50))) %>%   #number of samples - fixed at 5000
       cbind(as.numeric(rep(1 , 7*50))) %>%      #delta for alternative hypothesis - fixed at 1
       cbind(1:(7*50)) %>%                       #iteration tracker
       data.frame %>%                             #make into dataframe
       cbind(c(rep("normal" , 50) , rep("heavy" , 50) , rep("outlier" , 50) , 
                      rep("g0h0" , 50) , rep("g2h0" , 50) , rep("g0h2" , 50) , 
                      rep("g2h2" , 50))) %>%     #distribution label
       setNames(c("sam_size" , "num_sam" , "delta" , "tracker.i" , "data")) #label columns




#function for generating t-statistics
t_stat <- function(sam_size, num_sam , delta , tracker.i , data) {
       #extract name of current distribution for storage and later comparison
       distribution <- names(full.pop)[which(names(full.pop) %in% data)]
       
       #print information to console for tracking progress of t-statistic simulation
       cat("distribution = " , distribution , 
           " , sample size = " , sam_size , 
           " , i = " , tracker.i , 
           "\n")
       
       #establish current population from full list using distribution label
       data <- full.pop[[distribution]]
       
       #initialize blank matrix for simulated samples
       mat <- matrix(nrow = sam_size , ncol = num_sam)
       
       #fill each column with a sample of specified size
       for(i in 1:ncol(mat)) {
              mat[ , i] <- sample(data[["population"]] , sam_size , replace = F)
       }
       
       #generate population mean for given distribution
       mu0 <- mean(data[["population"]])
       
       #generate alternative-hypothesis mean for given delta and given population mean
       muA <- mu0 + delta
       
       #generate sample means
       xbar <- colMeans(mat)
       
       #generate sample standard deviations
       s <- apply(mat , 2 , sd)
       
       #generate sample t-scores
       t <- (xbar - mu0) / (s / sqrt(sam_size))
       
       #generate corresponding p-values for testing against
       # #true population mean
       p.vals0 <- mat %>%
              data.frame() %>%
              map(t.test , mu = mu0) %>%
              map_dbl("p.value") %>%
              as.numeric()
       
       #generate corresponding p-values for testing against
       # #alternative hypothesis with delta = 1
       p.valsA <- mat %>%
              data.frame() %>%
              map(t.test , mu = muA) %>%
              map_dbl("p.value") %>%
              as.numeric()
       
       #store all data to dataframe
       data <- data.frame(#(matrix(nrow = num_sam)) , 
                          distribution = distribution , sam_size = sam_size , num_sam = num_sam , 
                          mu0 = mu0 , muA = muA , delta = delta , 
                          xbar = xbar , s = s , t = t , 
                          p.vals0 = p.vals0 , p.valsA = p.valsA)
       
       #save dataframe to permanent object
       return(data)

}

#map t-statistic function over all simulation conditions
simulated.data <- sim.conds %>%
       pmap(t_stat)


#function for generating true probability coverage, type I, power
tcov <- function(data , conf.level = .95) {
       #print information to console for tracking progress of simulation
       cat("distribution = " , levels(data[ , "distribution"])[1] , 
           " , sample size = " , data[1 , "sam_size"] , 
           "\n")
       
       #set degrees of freedom for theoretical t-distribution: n-1
       df <- (data[1 , "sam_size"] - 1)
       
       #set upper quantile for theoretical CI
       conf.hi <- 1 - (1 - conf.level) / 2
       
       #set lower quantile for theoretical CI
       conf.lo <- 1 - conf.hi
       
       #sort simulated t-statistics
       t_statistics <- sort(data[ , "t"])
       
       #store current null-hypothesis p-vals
       # #to object for convenience
       p.vals0 <- data[ , "p.vals0"]
       
       #store current alt-hypothesis p-vals
       # #to object for convenience
       p.valsA <- data[ , "p.valsA"]
       
       #store delta
       # #to object for convenience
       delta <- data[1 , "delta"]
       
       #store arguments for "power.t.test"
       # #to object for convenience
       power.args <- list(delta = delta , 
                          sd = data[ , "s"] , 
                          sig.level = rep(conf.level , times = data[1 , "num_sam"]) , 
                          n = rep(data[1 , "sam_size"] , times = data[1 , "num_sam"]))
       
       #calculate nominal power level for each sample to detect
       # #delta
       nominal.power <- power.args %>%
              pmap(power.t.test) %>%
              map_dbl("power")
       #calculate actual power level for given data condition overall
       # #aka the rate of rejections to the total number of samples
       power <- sum(p.valsA < 0.05) / length(p.valsA)
       
       #calculate the actual probability coverage of the 95% CI
       # #in given data condition
       actual_prob <- length(which(t_statistics >= qt(conf.lo , df = df) &
                                          t_statistics <= qt(conf.hi,df = df))) / length(t_statistics)

       #calculate actual Type I error rate for given data condition + model
       # #aka the rate of rejections to the total number of samples
       typeI <- sum(p.vals0 < 0.05) / length(p.vals0)
       
       #store simulation data to dataframe
       sim.data <- data.frame(distribution = data[1 , "distribution"] , 
                              samplesize = data[1 , "sam_size"] , 
                              TypeI = typeI , 
                              nominalpower = mean(nominal.power) , 
                              actualpower = power)
       
       #save simulation to permanent object
       return(sim.data)
}

#generate type I error rates and power for all simulated samples
perf.data <- simulated.data %>%
       map_dfr(tcov)



#plot sim results: Type I error
typeI.plot <- ggplot(data = perf.data) + 
       geom_smooth(mapping = aes(x = samplesize, y = TypeI, color = distribution) , se = FALSE)
typeI.plot + coord_cartesian(ylim = c(0 , 0.20)) +
        xlab("Sample Size") + ylab("Type I") + 
        ggtitle("Type I Error Rate") + theme(plot.title = element_text(hjust = 0.5)) +
        scale_color_discrete(name = "Distribution",
                            breaks = c("normal" , "heavy" , "outlier" , "g0h0" , "g2h0" , "g0h2" , "g2h2"),
                            labels = c("Standard\nNormal", "Heavy-Tailed\nNormal", "Outlier-Contaminated\nNormal" , 
                                       "g-and-h(0,0)\naka Standard Normal" , "g-and-h(0.2,0)" , "g-and-h(0,0.2)" , "g-and-h(0.2,0.2)"))

#plot sim results: Power
# #generate and store plot objects
nominalpower.plot <- ggplot(data = perf.data) + 
       geom_smooth(mapping = aes(x = samplesize, y = nominalpower , color = distribution) , se = FALSE)
nominalpower.plot + coord_cartesian(ylim = c(0 , 1.0))

actualpower.plot <- ggplot(data = perf.data) + 
       geom_smooth(mapping = aes(x = samplesize, y = actualpower , color = distribution) , se = FALSE)
actualpower.plot + coord_cartesian(ylim = c(0 , 1.0))

# #generate legend for combined
newlegend.plot <- nominalpower.plot +
        scale_color_discrete(name = "Distribution",
                             breaks = c("normal" , "heavy" , "outlier" , "g0h0" , "g2h0" , "g0h2" , "g2h2"),
                             labels = c("Standard\nNormal", "Heavy-Tailed\nNormal", "Outlier-Contaminated\nNormal" , 
                                        "g-and-h(0,0)\naka Standard Normal" , "g-and-h(0.2,0)" , "g-and-h(0,0.2)" , "g-and-h(0.2,0.2)"))

#function which stores legend from plot into object for subsequent use
g_legend<-function(a.gplot){
       tmp <- ggplot_gtable(ggplot_build(a.gplot))
       leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
       legend <- tmp$grobs[[leg]]
       return(legend)}
mylegend <- g_legend(newlegend.plot)

#generate simultaneous plot of nominal + actual power + stored legend
grid.arrange(arrangeGrob((nominalpower.plot + 
                     coord_cartesian(ylim = c(0 , 1.0)) + 
                     xlab("Sample Size") + ylab("Power") + 
                     theme(legend.position = "none") + ggtitle("Nominal Power") + 
                             theme(plot.title = element_text(hjust = 0.5))) , 
             (actualpower.plot + 
                    coord_cartesian(ylim = c(0 , 1.0)) + 
                    xlab("Sample Size") + ylab("Power")  + 
                     theme(legend.position = "none") + ggtitle("Actual Power") + 
                      theme(plot.title = element_text(hjust = 0.5))) , 
             nrow = 1) , mylegend , ncol = 2 , widths = c(200 , 40))
```

